{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a25862d6",
   "metadata": {},
   "source": [
    "## 1. Set up environment\n",
    "\n",
    "Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0501ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "import re\n",
    "import requests\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcacdfda",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/alexisperrier/intro2nlp/master/data/Shakespeare_alllines.txt'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "# Read the file into list of lines \n",
    "lines = r.text.encode('ascii',errors='ignore').decode('utf-8').split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c26d8d",
   "metadata": {},
   "source": [
    "Remove all punctuation and only keep verses with more than one token to reduce the size of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c644bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This gives :  108805 sentences\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "for line in lines:\n",
    "    \n",
    "    # Remove punctuations\n",
    "    line = re.sub(r'[\\!\"#$%&\\*+,-./:;<=>?@^_`()|~=]', ' ', line)\n",
    "    \n",
    "    # simple toknizer\n",
    "    tokens = re.findall(r'\\b\\w+\\b', line)\n",
    "    \n",
    "    # Only keep lines with tokens >1\n",
    "    if len(tokens) > 1:\n",
    "        sentences.append(tokens)\n",
    "        \n",
    "\n",
    "print(\"This gives : \", len(sentences), \"sentences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe6dd65",
   "metadata": {},
   "source": [
    "Lets train the `word2Vec` model which we call it `bard2Vec`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38fb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "bard2Vec = Word2Vec(\n",
    "    sentences,\n",
    "    min_count = 3, # Ignore the words that appears less than 3 times\n",
    "    vector_size = 50, # Dimensionality of word embeddings\n",
    "    sg = 1, # skipgrams\n",
    "    window = 7, # Context window for words during training\n",
    "    epochs = 40 # Number of epochs training over corpus\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18db617",
   "metadata": {},
   "source": [
    "Once the training is done, we can explore the results by looking at word similarity for certain word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60785914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----most similar words to :  King\n",
      "\t     Henry 0.84\n",
      "\t    Edward 0.82\n",
      "\t   Richard 0.75\n",
      "\t   England 0.71\n",
      "\t     Pepin 0.7\n",
      "\t    Naples 0.69\n",
      "\t    Fourth 0.68\n",
      "\t   Warwick 0.68\n",
      "\t     Ghost 0.66\n",
      "\t     Sixth 0.66\n",
      "\n",
      "----most similar words to :  sword\n",
      "\t      head 0.75\n",
      "\t  Parthian 0.67\n",
      "\t    finger 0.67\n",
      "\t   stirrup 0.65\n",
      "\t       leg 0.65\n",
      "\t       Tie 0.64\n",
      "\t     edged 0.64\n",
      "\t       axe 0.63\n",
      "\t    pistol 0.63\n",
      "\t      hand 0.63\n",
      "\n",
      "----most similar words to :  husband\n",
      "\t      wife 0.87\n",
      "\t  daughter 0.78\n",
      "\t    mother 0.78\n",
      "\t  mistress 0.77\n",
      "\t    father 0.77\n",
      "\t    master 0.77\n",
      "\t   Orlando 0.74\n",
      "\t       son 0.74\n",
      "\t    sister 0.72\n",
      "\tbequeathed 0.72\n",
      "\n",
      "----most similar words to :  Hamlet\n",
      "\t   Laertes 0.69\n",
      "\t  Gertrude 0.69\n",
      "\t    cousin 0.67\n",
      "\t     chuck 0.67\n",
      "\t  Gramercy 0.66\n",
      "\t  Eglamour 0.64\n",
      "\t   bawcock 0.63\n",
      "\t  Popilius 0.63\n",
      "\t  Hereford 0.63\n",
      "\t   Stanley 0.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def similar_words(word):\n",
    "    print(\"----most similar words to : \", word)\n",
    "    for (token, score) in bard2Vec.wv.most_similar(word):\n",
    "        print(f\"\\t{token:>10} {np.round(score, 2)}\")\n",
    "    print()\n",
    "    \n",
    "similar_words('King')\n",
    "similar_words('sword')\n",
    "similar_words('husband')\n",
    "similar_words('Hamlet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce366d61",
   "metadata": {},
   "source": [
    "The results are dependent on how we trained the model. Let's compare with a model that is trained for a longer time and for larger window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f670f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "bard2vec = Word2Vec(\n",
    "         sentences,\n",
    "         min_count=3,   # same\n",
    "         vector_size=50,  # same\n",
    "         sg = 0,        # cbow instead of skip-grams\n",
    "         window=10,      # larger context windows\n",
    "         epochs=100)       # longer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5c89478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- most similar words to:  King\n",
      "\t    Fourth 0.62\n",
      "\t      vial 0.62\n",
      "\t     Queen 0.6\n",
      "\t  Scotland 0.59\n",
      "\t     Sixth 0.57\n",
      "\t   mockery 0.56\n",
      "\t     Gaunt 0.55\n",
      "\t    Europa 0.54\n",
      "\t      Earl 0.53\n",
      "\t   Macduff 0.53\n",
      "\n",
      "-- most similar words to:  sword\n",
      "\t      head 0.77\n",
      "\t    weapon 0.7\n",
      "\t     horse 0.68\n",
      "\t    dagger 0.67\n",
      "\t    rapier 0.66\n",
      "\t     heart 0.65\n",
      "\t    finger 0.64\n",
      "\t     knife 0.64\n",
      "\t      life 0.64\n",
      "\t    tongue 0.62\n",
      "\n",
      "-- most similar words to:  husband\n",
      "\t      wife 0.86\n",
      "\t  mistress 0.85\n",
      "\t    mother 0.84\n",
      "\t  daughter 0.82\n",
      "\t    friend 0.81\n",
      "\t   brother 0.8\n",
      "\t    sister 0.8\n",
      "\t       son 0.8\n",
      "\t    master 0.78\n",
      "\t    father 0.78\n",
      "\n",
      "-- most similar words to:  Hamlet\n",
      "\tNorthumberland 0.65\n",
      "\t  Polonius 0.63\n",
      "\tCanterbury 0.61\n",
      "\t Worcester 0.6\n",
      "\t  Gertrude 0.6\n",
      "\t   Suffolk 0.54\n",
      "\tGloucester 0.54\n",
      "\t  Clifford 0.54\n",
      "\t  Hastings 0.53\n",
      "\t Demetrius 0.53\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def similar_words(word):\n",
    "    print(\"-- most similar words to: \", word)\n",
    "    for (token, score) in bard2vec.wv.most_similar(word):\n",
    "        print(f\"\\t{token:>10} {np.round(score,2)}\")\n",
    "    print()\n",
    "    \n",
    "similar_words('King')\n",
    "similar_words('sword')\n",
    "similar_words('husband')\n",
    "similar_words('Hamlet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b087b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
